<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
   <HEAD>
      <TITLE>My first HTML document</TITLE>
      <style rel="stylesheet" type="text/css">
body {
 font-size: 23px;
 margin-top: 50px;
    margin-bottom: 50px;
    margin-right: 80px;
    margin-left: 80px;
    padding-top: 50px;
    padding-bottom: 50px;
    padding-right: 80px;
    padding-left: 80px;
    line-height:35px;background-color: black;color:#ABBAB7;
},
img {
 width:900px;
}
</style>
      <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    "HTML-CSS" : {
        availableFonts : ["STIX"],
        preferredFont : "STIX",
        webFont : "STIX-Web",
        imageFont : null
    }
});
</script>
     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">
    MathJax.Hub.Config({
        HTML: ["input/TeX","output/HTML-CSS"],
        TeX: { extensions: ["AMSmath.js","AMSsymbols.js"],
               equationNumbers: { autoNumber: "AMS" } },
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: { inlineMath: [ ['$$$','$$$'] ],
                   displayMath: [ ['$$$$','$$$$'] ],
                   processEscapes: true },
        "HTML-CSS": { availableFonts: ["TeX"],
                      linebreaks: { automatic: true } }
    });
</script>
   </HEAD>
   <BODY>
007_002_lab_DQN 2 (Nature 2015).html
<xmp>
# https://www.youtube.com/watch?v=ByB49iDMiZE&list=PLlMkM4tgfjnKsCWav-Z2F-MMFRx-2gMGG&index=16

# @
# DQN (2013):
# 1. Go deep
# 1. You use replay memory storing values
# to resolve correlations between samples

# DQN (2015):
# 1. Separate networks,
# to resolve non-stationary target issue

# Core idea of DQN 2013
# img 2018-04-29 16-50-01.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 16-50-01.png"><xmp>

# Core idea of DQN 2015
# img 2018-04-29 16-50-37.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 16-50-37.png"><xmp>


# @
# How to create separated networks
# img 2018-04-29 16-51-24.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 16-51-24.png"><xmp>

# @
# DQN vs targetDQN
# img 2018-04-29 16-52-22.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 16-52-22.png"><xmp>

# @
# How to handle two networks with codes
# img 2018-04-29 16-54-35.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 16-54-35.png"><xmp>

# @
# Copying network means copying value of weights
# img 2018-04-29 16-56-59.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 16-56-59.png"><xmp>

# @
# Summary
# 1. You create 2 networks
# 1. You make target same with main network
# target=mainNet
# 1. Environment, loop, ...
# When you create y, you will use target network
# You will update main network by using y
# 1. You make target network same with main network,
# by assigning main network into target network



# @
# Code related to replay train (targetDQN added)
# img 2018-04-29 17-01-39.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-01-39.png"><xmp>

# @
# Code related to copy network (variable)
# img 2018-04-29 17-02-23.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-02-23.png"><xmp>

# Code related to bot play
# img 2018-04-29 17-02-57.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-02-57.png"><xmp>

# Code related to main()
# img 2018-04-29 17-03-49.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-03-49.png"><xmp>

# Exercise 1
# Tuning hyper parameters (learning rate, sample size, decay factor)
# Network structure
    # add bias
    # test tanh, sigmoid, relu, etc
    # improve TF network to reduce sess.run() calls
# Reward redesign
# img 2018-04-29 17-06-37.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-06-37.png"><xmp>

# Exercise 2
# Car race with DQN 2015
# img 2018-04-29 17-07-20.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-07-20.png"><xmp>

# Exercise 3
# DQN implementtations
# Other games
# RMA approach
# img 2018-04-29 17-08-00.png
# </xmp><img src="/media/young/5e7be152-8ed5-483d-a8e8-b3fecfa221dc/text/mycodehtml/pracrl/shkim-rl/pic/2018-04-29 17-08-00.png"><xmp>


</xmp>
   </BODY>
</HTML>
